{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmm.hmm import HMM\n",
    "from hmm.learning import expectation_maximisation_hard_assignment, learn_parameters_everything_observed\n",
    "from hmm.types import IntArray\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.1\n",
    "beta = 0.2\n",
    "alpha = 0.01\n",
    "rates = [1, 20]\n",
    "\n",
    "# This is uppercase-gamma.\n",
    "transition_matrix = np.array(\n",
    "    [[1 - gamma, 0, gamma], [0, 1 - gamma, gamma], [beta / 2, beta / 2, 1 - beta]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = HMM(transition_matrix, alpha, processing_modes=[0, 1, 2], rates=rates)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 8\n",
    "time_steps = 100\n",
    "initial_c = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_processing_modes, observed_focus, observed_stimuli = hmm.forward(\n",
    "    num_nodes,\n",
    "    time_steps,\n",
    "    initial_c,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning with everything observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is necessary for mask computation.\n",
    "observed_processing_modes: IntArray = np.array(observed_processing_modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    lambda_0_hat,\n",
    "    lambda_1_hat,\n",
    "    learned_alpha,\n",
    "    learned_beta,\n",
    "    learned_gamma\n",
    ") = learn_parameters_everything_observed(\n",
    "    observed_processing_modes,\n",
    "    observed_focus,\n",
    "    observed_stimuli\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learned parameters ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1383,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_rates = [lambda_0_hat, lambda_1_hat]\n",
    "learned_transition_matrix = np.array(\n",
    "    [[1 - learned_gamma, 0, learned_gamma],\n",
    "     [0, 1 - learned_gamma, learned_gamma],\n",
    "     [learned_beta / 2, learned_beta / 2, 1 - learned_beta]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_hmm = HMM(\n",
    "    transition=learned_transition_matrix,\n",
    "    alpha=learned_alpha,\n",
    "    processing_modes=hmm.states,\n",
    "    rates=learned_rates\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the learned model (everything observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_processing_modes, true_focus, observations = hmm.forward(\n",
    "    num_nodes,\n",
    "    time_steps,\n",
    "    initial_c,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_joint_prob = hmm.infer(observations)\n",
    "learned_joint_prob = learned_hmm.infer(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal_prob_C = np.sum(learned_joint_prob, axis=2)\n",
    "\n",
    "estimated_C = np.argmax(marginal_prob_C, axis=1)\n",
    "estimated_Z = np.zeros((time_steps, num_nodes), dtype=int)\n",
    "\n",
    "for t, c in enumerate(estimated_C):\n",
    "    estimated_Z[t] = learned_hmm.sample_hidden_z(num_nodes, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of correct C estimations: 0.69\n",
      "Proportion of correct Z estimations: 0.76\n"
     ]
    }
   ],
   "source": [
    "correct_C = np.sum(np.equal(estimated_C, true_processing_modes[:-1])) / (time_steps - 1)\n",
    "correct_Z = np.sum(estimated_Z == true_focus) / ((time_steps - 1) * num_nodes)\n",
    "\n",
    "print(f\"Proportion of correct C estimations: {correct_C:.2f}\")\n",
    "print(f\"Proportion of correct Z estimations: {correct_Z:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning just from $\\textbf{X}$ (full learning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute $\\hat{Z}_{t,i} = \\argmax_z P(Z_{t,i} = z | \\textbf{X} = \\textbf{x})$ and $\\hat{C}_t = \\argmax_z P(C_t = z | \\textbf{X} = \\textbf{x})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whatever. We're just using some joint-prob, taking from above. :)\n",
    "z_hat, c_hat = expectation_maximisation_hard_assignment(\n",
    "    original_joint_prob, num_nodes=num_nodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 8)"
      ]
     },
     "execution_count": 1390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_hat.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1391,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs: int = 10 # lol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = HMM(transition_matrix, alpha, processing_modes=[0, 1, 2], rates=rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(epochs):\n",
    "    joint_prob = hmm.infer(observations)\n",
    "    z_hat, c_hat = expectation_maximisation_hard_assignment(joint_prob, num_nodes=num_nodes)\n",
    "\n",
    "    (\n",
    "        lambda_0_hat,\n",
    "        lambda_1_hat,\n",
    "        learned_alpha,\n",
    "        learned_beta,\n",
    "        learned_gamma\n",
    "    ) = learn_parameters_everything_observed(\n",
    "        c_hat,\n",
    "        z_hat,\n",
    "        observations[:-1]\n",
    "    )\n",
    "\n",
    "    learned_rates = [lambda_0_hat, lambda_1_hat]\n",
    "    learned_transition_matrix = np.array(\n",
    "        [[1 - learned_gamma, 0, learned_gamma],\n",
    "        [0, 1 - learned_gamma, learned_gamma],\n",
    "        [learned_beta / 2, learned_beta / 2, 1 - learned_beta]]\n",
    "    )\n",
    "\n",
    "    hmm = HMM(learned_transition_matrix, alpha=learned_alpha, processing_modes=hmm.states, rates=learned_rates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_joint_prob = hmm.infer(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of correct C estimations: 0.57\n",
      "Proportion of correct Z estimations: 0.37\n"
     ]
    }
   ],
   "source": [
    "marginal_prob_C = np.sum(learned_joint_prob, axis=2)\n",
    "\n",
    "estimated_C = np.argmax(marginal_prob_C, axis=1)\n",
    "estimated_Z = np.zeros((time_steps, num_nodes), dtype=int)\n",
    "\n",
    "for t, c in enumerate(estimated_C):\n",
    "    estimated_Z[t] = hmm.sample_hidden_z(num_nodes, c)\n",
    "\n",
    "correct_C = np.sum(np.equal(estimated_C, true_processing_modes[:-1])) / (time_steps - 1)\n",
    "correct_Z = np.sum(estimated_Z == true_focus) / ((time_steps - 1) * num_nodes)\n",
    "\n",
    "print(f\"Proportion of correct C estimations: {correct_C:.2f}\")\n",
    "print(f\"Proportion of correct Z estimations: {correct_Z:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4379472f3a660c7857acec9d80a0eff9746fc7b3b3d0fd4e2cf71dae9af0e1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
