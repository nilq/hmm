{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmm.hmm import HMM\n",
    "from hmm.learning import hard_assignment_em, learn_parameters_everything_observed\n",
    "from hmm.types import IntArray\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.5\n",
    "beta = 0.8\n",
    "alpha = 0.9\n",
    "rates = [1, 20]\n",
    "\n",
    "# This is uppercase-gamma.\n",
    "transition_matrix = np.array(\n",
    "    [[1 - gamma, 0, gamma], [0, 1 - gamma, gamma], [beta / 2, beta / 2, 1 - beta]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = HMM(transition_matrix, alpha, processing_modes=[0, 1, 2], rates=rates)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 8\n",
    "time_steps = 100\n",
    "initial_c = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_processing_modes, observed_focus, observed_stimuli = hmm.forward(\n",
    "    num_nodes,\n",
    "    time_steps,\n",
    "    initial_c,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning with everything observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is necessary for mask computation.\n",
    "observed_processing_modes: IntArray = np.array(observed_processing_modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    lambda_0_hat,\n",
    "    lambda_1_hat,\n",
    "    learned_alpha,\n",
    "    learned_beta,\n",
    "    learned_gamma\n",
    ") = learn_parameters_everything_observed(\n",
    "    observed_processing_modes,\n",
    "    observed_focus,\n",
    "    observed_stimuli\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learned parameters ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_rates = [lambda_0_hat, lambda_1_hat]\n",
    "learned_transition_matrix = np.array(\n",
    "    [[1 - learned_gamma, 0, learned_gamma],\n",
    "     [0, 1 - learned_gamma, learned_gamma],\n",
    "     [learned_beta / 2, learned_beta / 2, 1 - learned_beta]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_hmm = HMM(\n",
    "    transition=learned_transition_matrix,\n",
    "    alpha=learned_alpha,\n",
    "    processing_modes=hmm.processing_modes,\n",
    "    rates=learned_rates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found good after 5 iterations!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niels/Documents/GitHub/hmm/hmm/hmm.py:234: RuntimeWarning: invalid value encountered in divide\n",
      "  beta_cs[t] /= beta_cs[t].sum()\n"
     ]
    }
   ],
   "source": [
    "learned_hmm = hard_assignment_em(observed_stimuli, observed_focus, HMM(transition_matrix, alpha, processing_modes=[0, 1, 2], rates=rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True alpha: 0.9, Learned alpha: 0.42\n",
      "True rates: [1, 20], Learned rates: [1.0229885057471264, 20.279452054794522]\n",
      "True transition matrix:\n",
      "[[0.5 0.  0.5]\n",
      " [0.  0.5 0.5]\n",
      " [0.4 0.4 0.2]]\n",
      "Learned transition matrix:\n",
      "[[0.82828283 0.         0.17171717]\n",
      " [0.         0.82828283 0.17171717]\n",
      " [0.08585859 0.08585859 0.82828283]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"True alpha: {hmm.alpha}, Learned alpha: {learned_hmm.alpha}\")\n",
    "print(f\"True rates: {hmm.rates}, Learned rates: {learned_hmm.rates}\")\n",
    "print(f\"True transition matrix:\\n{hmm.transition}\")\n",
    "print(f\"Learned transition matrix:\\n{learned_hmm.transition}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the learned model (everything observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_processing_modes, true_focus, observations = hmm.forward(\n",
    "    num_nodes,\n",
    "    time_steps,\n",
    "    initial_c,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_marginals_c, original_marginals_z = hmm.nielslief_propagation(observations)\n",
    "learned_marginals_c, learned_marginals_z = learned_hmm.nielslief_propagation(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_marginals_c, original_marginals_z = hmm.nielslief_propagation(observations)\n",
    "learned_marginals_c, learned_marginals_z = learned_hmm.nielslief_propagation(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correctness(marginals_c, marginals_z, hmm_to_use) -> None:\n",
    "    estimated_C = np.argmax(marginals_c, axis=1)\n",
    "    # Compute the most likely Z given the estimated C\n",
    "    estimated_Z = np.zeros((time_steps, num_nodes), dtype=int)\n",
    "\n",
    "    for t, c in enumerate(estimated_C):\n",
    "        estimated_Z[t] = hmm_to_use.sample_hidden_z(num_nodes, c)\n",
    "\n",
    "    correct_C = np.sum(np.equal(estimated_C, true_processing_modes)) / (time_steps - 1)\n",
    "    correct_Z = np.sum(true_focus == estimated_Z) / (time_steps * num_nodes)\n",
    "\n",
    "    print(f\"Proportion of correct C estimations: {correct_C:.2f}\")\n",
    "    print(f\"Proportion of correct Z estimations: {correct_Z:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of correct C estimations: 0.91\n",
      "Proportion of correct Z estimations: 0.70\n",
      "Proportion of correct C estimations: 0.78\n",
      "Proportion of correct Z estimations: 0.46\n"
     ]
    }
   ],
   "source": [
    "check_correctness(original_marginals_c, original_marginals_z, hmm)\n",
    "check_correctness(learned_marginals_c, learned_marginals_z, learned_hmm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning just from $\\textbf{X}$ (full learning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute $\\hat{Z}_{t,i} = \\argmax_z P(Z_{t,i} = z | \\textbf{X} = \\textbf{x})$ and $\\hat{C}_t = \\argmax_z P(C_t = z | \\textbf{X} = \\textbf{x})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expectation_maximisation_hard_assignment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Whatever. We're just using some joint-prob, taking from above. :)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m z_hat, c_hat \u001b[39m=\u001b[39m expectation_maximisation_hard_assignment(\n\u001b[1;32m      3\u001b[0m     estimated_C, estimated_Z, num_nodes\u001b[39m=\u001b[39mnum_nodes\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'expectation_maximisation_hard_assignment' is not defined"
     ]
    }
   ],
   "source": [
    "# Whatever. We're just using some joint-prob, taking from above. :)\n",
    "z_hat, c_hat = expectation_maximisation_hard_assignment(\n",
    "    estimated_C, estimated_Z, num_nodes=num_nodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_hat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs: int = 10 # lol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = HMM(transition_matrix, alpha, processing_modes=[0, 1, 2], rates=rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m      2\u001b[0m     joint_prob \u001b[39m=\u001b[39m hmm\u001b[39m.\u001b[39minfer(observations)\n\u001b[1;32m      3\u001b[0m     z_hat, c_hat \u001b[39m=\u001b[39m expectation_maximisation_hard_assignment(joint_prob, num_nodes\u001b[39m=\u001b[39mnum_nodes)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "for _ in range(epochs):\n",
    "    joint_prob = hmm.infer(observations)\n",
    "    z_hat, c_hat = expectation_maximisation_hard_assignment(joint_prob, num_nodes=num_nodes)\n",
    "\n",
    "    (\n",
    "        lambda_0_hat,\n",
    "        lambda_1_hat,\n",
    "        learned_alpha,\n",
    "        learned_beta,\n",
    "        learned_gamma\n",
    "    ) = learn_parameters_everything_observed(\n",
    "        c_hat,\n",
    "        z_hat,\n",
    "        observations[:-1]\n",
    "    )\n",
    "\n",
    "    learned_rates = [lambda_0_hat, lambda_1_hat]\n",
    "    learned_transition_matrix = np.array(\n",
    "        [[1 - learned_gamma, 0, learned_gamma],\n",
    "        [0, 1 - learned_gamma, learned_gamma],\n",
    "        [learned_beta / 2, learned_beta / 2, 1 - learned_beta]]\n",
    "    )\n",
    "\n",
    "    hmm = HMM(learned_transition_matrix, alpha=learned_alpha, processing_modes=hmm.states, rates=learned_rates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_joint_prob = hmm.infer(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of correct C estimations: 0.57\n",
      "Proportion of correct Z estimations: 0.37\n"
     ]
    }
   ],
   "source": [
    "marginal_prob_C = np.sum(learned_joint_prob, axis=2)\n",
    "\n",
    "estimated_C = np.argmax(marginal_prob_C, axis=1)\n",
    "estimated_Z = np.zeros((time_steps, num_nodes), dtype=int)\n",
    "\n",
    "for t, c in enumerate(estimated_C):\n",
    "    estimated_Z[t] = hmm.sample_hidden_z(num_nodes, c)\n",
    "\n",
    "correct_C = np.sum(np.equal(estimated_C, true_processing_modes[:-1])) / (time_steps - 1)\n",
    "correct_Z = np.sum(estimated_Z == true_focus) / ((time_steps - 1) * num_nodes)\n",
    "\n",
    "print(f\"Proportion of correct C estimations: {correct_C:.2f}\")\n",
    "print(f\"Proportion of correct Z estimations: {correct_Z:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4379472f3a660c7857acec9d80a0eff9746fc7b3b3d0fd4e2cf71dae9af0e1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
