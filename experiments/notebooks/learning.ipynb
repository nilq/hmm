{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmm.hmm import HMM\n",
    "from hmm.learning import hard_assignment_em, learn_parameters_everything_observed\n",
    "from hmm.types import IntArray\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.1\n",
    "beta = 0.2\n",
    "alpha = 0.6\n",
    "rates = [1, 5]\n",
    "\n",
    "# This is uppercase-gamma.\n",
    "transition_matrix = np.array(\n",
    "    [[1 - gamma, 0, gamma], [0, 1 - gamma, gamma], [beta / 2, beta / 2, 1 - beta]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = HMM(transition_matrix, alpha, processing_modes=[0, 1, 2], rates=rates)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 8\n",
    "time_steps = 1000\n",
    "initial_c = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_processing_modes, observed_focus, observed_stimuli = hmm.forward(\n",
    "    num_nodes,\n",
    "    time_steps,\n",
    "    initial_c,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning with everything observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is necessary for mask computation.\n",
    "observed_processing_modes: IntArray = np.array(observed_processing_modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    lambda_0_hat,\n",
    "    lambda_1_hat,\n",
    "    learned_alpha,\n",
    "    learned_beta,\n",
    "    learned_gamma\n",
    ") = learn_parameters_everything_observed(\n",
    "    observed_processing_modes,\n",
    "    observed_focus,\n",
    "    observed_stimuli\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_focus.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learned parameters ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_rates = [lambda_0_hat, lambda_1_hat]\n",
    "learned_transition_matrix = np.array(\n",
    "    [[1 - learned_gamma, 0, learned_gamma],\n",
    "     [0, 1 - learned_gamma, learned_gamma],\n",
    "     [learned_beta / 2, learned_beta / 2, 1 - learned_beta]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_hmm = HMM(\n",
    "    transition=learned_transition_matrix,\n",
    "    alpha=learned_alpha,\n",
    "    processing_modes=hmm.processing_modes,\n",
    "    rates=learned_rates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_focus = np.random.randn(*observed_focus.shape) > 0.5\n",
    "random_focus = random_focus.astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Den her fejler lidt tilfÃ¦ldigt, sÃ¥ scroll lidt lÃ¦ngere ned for at finde en til at debugge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_hmm = hard_assignment_em(observed_stimuli, HMM(transition_matrix, alpha, processing_modes=[0, 1, 2], rates=rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"True alpha: {hmm.alpha:.2}, Learned alpha: {learned_hmm.alpha:.2}\")\n",
    "print(f\"True rates: {hmm.rates}, Learned rates: {learned_hmm.rates}\")\n",
    "print(f\"True beta: {beta:.2}, Learned beta: {learned_beta:.2}\")\n",
    "print(f\"True gamma: {gamma:.2}, Learned gamma: {learned_gamma:.2}\")\n",
    "print(f\"True transition matrix:\\n{hmm.transition}\")\n",
    "print(f\"Learned transition matrix:\\n{learned_hmm.transition}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEY NIELS ðŸ™‹ðŸ¿â€â™€ï¸ðŸ™‹ðŸ¼â€â™‚ï¸\n",
    "Den her gÃ¸r det nemmere at debugge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_processing_modes, true_focus, observations = hmm.forward(\n",
    "    num_nodes,\n",
    "    time_steps,\n",
    "    initial_c,\n",
    ")\n",
    "\n",
    "rand_gamma = 0.45 # > 0.5 is bad\n",
    "rand_beta = 0.4\n",
    "rand_alpha = 0.56\n",
    "rand_rates = [1, 5]\n",
    "\n",
    "# This is uppercase-gamma.\n",
    "rand_transition_matrix = np.array(\n",
    "    [[1 - rand_gamma, 0, rand_gamma], [0, 1 - rand_gamma, rand_gamma], [rand_beta / 2, rand_beta / 2, 1 - rand_beta]]\n",
    ")\n",
    "\n",
    "h0 = HMM(rand_transition_matrix, rand_alpha, processing_modes=[0, 1, 2], rates=rand_rates)\n",
    "c_marginals, z_marginals = learned_hmm.nielslief_propagation(observations)\n",
    "c_argmax = np.argmax(c_marginals, axis=1)\n",
    "c_diff = abs(c_argmax - true_processing_modes).sum()\n",
    "\n",
    "z_argmax = [[z[0] > z[1] for z in z_marg] for z_marg in z_marginals]\n",
    "z_argmax = np.array(z_argmax).astype(int)\n",
    "z_diff = abs(z_argmax - true_focus).sum()\n",
    "\n",
    "print(f\"iteration 0: c_diff={c_diff}, z_diff={z_diff}\")\n",
    "\n",
    "hmms = [(h0, c_diff, z_diff)]\n",
    "\n",
    "for i in range(10):\n",
    "    learned_hmm = hard_assignment_em(observations, HMM(rand_transition_matrix, rand_alpha, processing_modes=[0, 1, 2], rates=rand_rates), max_iterations=i)\n",
    "    c_marginals, z_marginals = learned_hmm.nielslief_propagation(observations)\n",
    "    c_argmax = np.argmax(c_marginals, axis=1)        \n",
    "    c_diff = abs(c_argmax - true_processing_modes).sum()\n",
    "\n",
    "    z_argmax = [[z[0] > z[1] for z in z_marg] for z_marg in z_marginals]\n",
    "    z_argmax = np.array(z_argmax).astype(int)\n",
    "    z_diff = abs(z_argmax - true_focus).sum()\n",
    "    \n",
    "    hmms.append((learned_hmm, c_diff, z_diff))\n",
    "    print(f\"iteration {i}: c_diff={c_diff}, z_diff={z_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([hmm[1] for hmm in hmms])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the learned model (everything observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_processing_modes, true_focus, observations = hmm.forward(\n",
    "    num_nodes,\n",
    "    time_steps,\n",
    "    initial_c,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_marginals_c, original_marginals_z = hmm.nielslief_propagation(observations)\n",
    "learned_marginals_c, learned_marginals_z = learned_hmm.nielslief_propagation(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_marginals_c, original_marginals_z = hmm.nielslief_propagation(observations)\n",
    "learned_marginals_c, learned_marginals_z = learned_hmm.nielslief_propagation(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correctness(marginals_c, marginals_z, hmm_to_use) -> None:\n",
    "    estimated_C = np.argmax(marginals_c, axis=1)\n",
    "    # Compute the most likely Z given the estimated C\n",
    "    estimated_Z = np.zeros((time_steps, num_nodes), dtype=int)\n",
    "\n",
    "    for t, c in enumerate(estimated_C):\n",
    "        estimated_Z[t] = hmm_to_use.sample_hidden_z(num_nodes, c)\n",
    "\n",
    "    correct_C = np.sum(np.equal(estimated_C, true_processing_modes)) / (time_steps - 1)\n",
    "    correct_Z = np.sum(true_focus == estimated_Z) / (time_steps * num_nodes)\n",
    "\n",
    "    print(f\"Proportion of correct C estimations: {correct_C:.2f}\")\n",
    "    print(f\"Proportion of correct Z estimations: {correct_Z:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_correctness(original_marginals_c, original_marginals_z, hmm)\n",
    "check_correctness(learned_marginals_c, learned_marginals_z, learned_hmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.genfromtxt(\"../../data/Ex_1.csv\", delimiter=\",\" ,dtype=int)[1:, 1:]\n",
    "\n",
    "original_marginals_c, original_marginals_z = hmm.nielslief_propagation(training_data)\n",
    "\n",
    "check_correctness(original_marginals_c, original_marginals_z, learned_hmm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning just from $\\textbf{X}$ (full learning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute $\\hat{Z}_{t,i} = \\argmax_z P(Z_{t,i} = z | \\textbf{X} = \\textbf{x})$ and $\\hat{C}_t = \\argmax_z P(C_t = z | \\textbf{X} = \\textbf{x})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whatever. We're just using some joint-prob, taking from above. :)\n",
    "z_hat, c_hat = hmm.nielslief_propagation(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_hat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs: int = 10 # lol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = HMM(transition_matrix, alpha, processing_modes=[0, 1, 2], rates=rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(epochs):\n",
    "    joint_prob = hmm.infer(observations)\n",
    "    z_hat, c_hat = expectation_maximisation_hard_assignment(joint_prob, num_nodes=num_nodes)\n",
    "\n",
    "    (\n",
    "        lambda_0_hat,\n",
    "        lambda_1_hat,\n",
    "        learned_alpha,\n",
    "        learned_beta,\n",
    "        learned_gamma\n",
    "    ) = learn_parameters_everything_observed(\n",
    "        c_hat,\n",
    "        z_hat,\n",
    "        observations[:-1]\n",
    "    )\n",
    "\n",
    "    learned_rates = [lambda_0_hat, lambda_1_hat]\n",
    "    learned_transition_matrix = np.array(\n",
    "        [[1 - learned_gamma, 0, learned_gamma],\n",
    "        [0, 1 - learned_gamma, learned_gamma],\n",
    "        [learned_beta / 2, learned_beta / 2, 1 - learned_beta]]\n",
    "    )\n",
    "\n",
    "    hmm = HMM(learned_transition_matrix, alpha=learned_alpha, processing_modes=hmm.states, rates=learned_rates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_joint_prob = hmm.infer(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal_prob_C = np.sum(learned_joint_prob, axis=2)\n",
    "\n",
    "estimated_C = np.argmax(marginal_prob_C, axis=1)\n",
    "estimated_Z = np.zeros((time_steps, num_nodes), dtype=int)\n",
    "\n",
    "for t, c in enumerate(estimated_C):\n",
    "    estimated_Z[t] = hmm.sample_hidden_z(num_nodes, c)\n",
    "\n",
    "correct_C = np.sum(np.equal(estimated_C, true_processing_modes[:-1])) / (time_steps - 1)\n",
    "correct_Z = np.sum(estimated_Z == true_focus) / ((time_steps - 1) * num_nodes)\n",
    "\n",
    "print(f\"Proportion of correct C estimations: {correct_C:.2f}\")\n",
    "print(f\"Proportion of correct Z estimations: {correct_Z:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29b1d4d6122c96d5fce1a151048f8a66e6e7aedbfdc7ce4b7dc5aa9ca27d69f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
